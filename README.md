# Task_05_Descriptive_Stats
This project explores match-level statistics from the IPL 2025 season using both Python and a Large Language Model (LLM), specifically ChatGPT. The main goal was to compare whether ChatGPT can deliver the same analytical outcomes as Python, and to observe any differences in accuracy, speed, or interpretation when working with structured datasets.

ChatGPT generally handled the small dataset efficiently and returned relevant results. However, some discrepancies were observed when compared with Python outputs. For instance, when asked whether there is a statistically significant advantage to bowling first versus batting first, ChatGPT returned a p-value of 0.83, while Python produced a slightly different result of 0.7848. Although the conclusion remained the same (no statistical significance, since p > 0.05), this minor inconsistency suggests that ChatGPT may approximate or round intermediate calculations differently than code-based statistical functions.

In another case, ChatGPT was asked to identify the venue with the most closely contested matches (defined as a margin less than 10 runs or 2 wickets). It initially returned an incorrect answer and took noticeably longer to generate a response. In contrast, Python correctly and quickly identified Vishakhapatnam as the venue with the most close finishes. This example highlights ChatGPTâ€™s limitations when it comes to precise filtering and comparison operations across large datasets.

While ChatGPT performed adequately with this small dataset, my previous experience with larger datasets showed that it often becomes slower and less reliable for handling structured data at scale. These observations reinforce the importance of validating LLM-generated insights using traditional coding methods, especially when the task involves numerical precision, performance metrics, or complex filtering logic.
